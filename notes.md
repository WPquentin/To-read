## Time series
Predicting GPU Failures With High Precision Under Deep Learning Workloads (https://arxiv.org/abs/2201.11853)

ByteDance, training and inference, GPT-3 and so on, V100 and P4 and T4, tens of thousands

Augment failure instances by sliding window

*Observation: failure pattern changes over time

Data collection: existing tools likve <code>nvidia-smi</code>, <code>dmesg</code>, and so on,

## Failure statistics

Analysis of Large-Scale Multi-Tenant GPU Clusters for DNN Training Workloads (https://www.usenix.org/conference/atc19/presentation/jeon)

https://arxiv.org/pdf/2403.07648

## Real traces
https://github.com/Azure/AzurePublicDataset/tree

*https://github.com/alibaba/clusterdata

https://github.com/InternLM/AcmeTrace

*https://github.com/S-Lab-System-Group/HeliosData

*https://github.com/msr-fiddle/philly-traces

https://ieeexplore.ieee.org/abstract/document/10485027 (contact zzhang@tacc.utexas.edu to obtain)

## Generated traces

https://dl.acm.org/doi/abs/10.1145/3650200.3656598

https://arxiv.org/abs/2108.03645

## For starters

https://www.usenix.org/conference/nsdi22/presentation/weng

https://www.usenix.org/conference/nsdi24/presentation/jiang-ziheng

## Performance

https://www.kaggle.com/datasets/ziya07/smart-meter-electricity-consumption-dataset

https://data.openei.org/submissions/180#:~:text=This%20project%20estimates%20hourly%20demand,a%20series%20of%20csv%20files

https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption





